{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42db3dd-ad97-4077-826f-dffd1653e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toturial for arxive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5484766-8d54-412f-8001-0a35c76843f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"secret key\"\n",
    "claude_api_key = \"secret key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f002837e-e4ac-458e-a427-c5c0b4e69118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "import arxiv\n",
    "import anthropic\n",
    "from openai import OpenAI\n",
    "\n",
    "##########################################################\n",
    "## Functions to interact with ArXiv and cache papers    ##\n",
    "##########################################################\n",
    "def fetch_papers(query, category=None, n_papers=20):\n",
    "    # Construct the API client\n",
    "    client = arxiv.Client()\n",
    "    \n",
    "    # Build the search query\n",
    "    search_query = query\n",
    "    if category:\n",
    "        search_query += f\" AND cat:{category}\"\n",
    "    \n",
    "    # Initialize the search\n",
    "    search = arxiv.Search(\n",
    "        query=search_query,\n",
    "        max_results=n_papers,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    \n",
    "    # Fetch the results\n",
    "    results = client.results(search)\n",
    "    \n",
    "    # Initialize a list to hold data dictionaries for each paper\n",
    "    papers = []\n",
    "    \n",
    "    for paper in results:\n",
    "        paper_data = {\n",
    "            'title': paper.title,\n",
    "            'abstract': paper.summary.replace('\\n', ' '),  # Replace new lines in abstracts with spaces\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'link': paper.entry_id  # Add this line to include the paper's URL\n",
    "        }\n",
    "        papers.append(paper_data)\n",
    "    return papers\n",
    "\n",
    "    \n",
    "def write_papers(papers, filename=\"./arxiv_papers.jsonl\"):\n",
    "    # Write data to a JSONL file. Replace with DB write if you want something more interesting\n",
    "    with open(filename, 'w') as outfile:\n",
    "        for paper_data in papers:\n",
    "            json.dump(paper_data, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "\n",
    "##########################################################\n",
    "## Functions to get responses from OpenAI and Anthropic ##\n",
    "##########################################################\n",
    "def get_openai(prompt,\n",
    "               model=\"gpt-3.5-turbo-0125\", \n",
    "               api_key=None, \n",
    "               system_prompt=\"You are a helpful assistant.\", \n",
    "               max_tokens=2000, \n",
    "               temperature=0.8):\n",
    "    # models \"gpt-4-turbo\", \"gpt-3.5-turbo-0125\"\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ],\n",
    "      temperature=temperature,\n",
    "      max_tokens=max_tokens,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_anthropic(prompt, \n",
    "                  model=\"claude-3-haiku-20240307\", \n",
    "                  api_key=None,\n",
    "                  system_prompt=\"You are a helpful assistant.\", \n",
    "                  max_tokens=2000, \n",
    "                  temperature=0):\n",
    "    # Other models \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"\n",
    "\n",
    "    client = anthropic.Anthropic(\n",
    "        api_key=api_key,\n",
    "    )\n",
    "    message = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=2000,\n",
    "        temperature=0,\n",
    "        system=f\"{system_prompt}\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "def get_streaming_anthropic(input_for_summary, \n",
    "                            model=\"claude-3-haiku-20240307\", \n",
    "                            api_key=None,\n",
    "                            system_prompt=\"You are a helpful assitant\", \n",
    "                            max_tokens=2000, \n",
    "                            temperature=0):\n",
    "\n",
    "    client = anthropic.Anthropic(api_key=claude_api_key)\n",
    "\n",
    "    response = \"\"\n",
    "    with client.messages.stream(\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        system=f\"{system_prompt}\",\n",
    "        messages=[{\"role\": \"user\", \"content\": input_for_summary}],\n",
    "        model=model,\n",
    "    ) as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text\n",
    "            clear_output(wait=True)\n",
    "            display(Markdown(response))\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a107896b-d447-489a-b1c2-bb370074c8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /opt/conda/lib/python3.11/site-packages (0.34.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from anthropic) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from anthropic) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from anthropic) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from anthropic) (2.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /opt/conda/lib/python3.11/site-packages (from anthropic) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from anthropic) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.14.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.11/site-packages (from tokenizers>=0.13.0->anthropic) (0.24.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.2.1)\n",
      "Requirement already satisfied: arxiv in /opt/conda/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in /opt/conda/lib/python3.11/site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in /opt/conda/lib/python3.11/site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in /opt/conda/lib/python3.11/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic\n",
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a08f8572-c859-4983-a0e5-81f1c2fd72bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Fetched 5 papers from ArXiv. ==> \n",
      "== Wrote papers to temporary cache at ./arxiv_papers.jsonl ==>\n"
     ]
    }
   ],
   "source": [
    "# fetch the data / collecting 40 papers \n",
    "query= \"au:blaiszik\"\n",
    "n_papers = 5\n",
    "category = \"\"\n",
    "db_file = './arxiv_papers.jsonl'\n",
    "\n",
    "papers = fetch_papers(query, category=category, n_papers=n_papers)\n",
    "print(f\"== Fetched {len(papers)} papers from ArXiv. ==> \")\n",
    "\n",
    "write_papers(papers, db_file)\n",
    "print(f\"== Wrote papers to temporary cache at {db_file} ==>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7cbdb5-e63f-4c4f-9322-b7ce6257bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = []\n",
    "with open('./arxiv_papers.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        papers.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ddceda-e22f-4c1b-9716-c23f44d09aae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Materials Properties with Accurate Predictions, Uncertainty Estimates, Domain Guidance, and Persistent Online Accessibility\n",
      "------------------\n",
      "Twins in rotational spectroscopy: Does a rotational spectrum uniquely identify a molecule?\n",
      "------------------\n",
      "Trillion Parameter AI Serving Infrastructure for Scientific Discovery: A Survey and Vision\n",
      "------------------\n",
      "Accelerating Electronic Stopping Power Predictions by 10 Million Times with a Combination of Time-Dependent Density Functional Theory and Machine Learning\n",
      "------------------\n",
      "Towards a Modular Architecture for Science Factories\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "for i in papers :\n",
    "    print(i[\"title\"])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb8cbf6-4444-4997-b69c-bc0b733e432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each papaer {title,abstract,authors,link}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d806b6ed-a484-46cd-aebe-531e9c06b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_summary = \"\"\"Summarize the following arXiv papers at the level of an advanced Ph.D. student, making interconnections between the papers where possible.\n",
    "                       First create a summary paragraph that includes the most important breakthroughs in the contained papers. \n",
    "                       Second, create a summary tweet thread describing the papers. \n",
    "                       Next, provide a section on interconnections where the information is grouped in a structured way that makes it easy to understand, rather than by each paper separately. \n",
    "                       Each paper should always be referenced by its link in markdown format. Be sure to include markdown style links to the papers and to references to the other papers. \n",
    "                       \\n\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e17db0-2196-4c02-b0ab-679074b3184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in papers:\n",
    "    input_for_summary += \"<paper>\\n\"\n",
    "    input_for_summary += f\"### {paper['title']}\\n\\n\"\n",
    "    input_for_summary += f\"**Abstract:** {paper['abstract']}\\n\\n\"\n",
    "    input_for_summary += f\"**Authors:** {', '.join(paper['authors'])}\\n\\n\"\n",
    "    input_for_summary += f\"[Link to paper]({paper['link']})\\n\\n\"\n",
    "    input_for_summary += \"</paper>\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7cddb32-9c68-44ec-83bc-f61e0215701a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Machine Learning Materials Properties with Accurate Predictions, Uncertainty Estimates, Domain Guidance, and Persistent Online Accessibility',\n",
       " 'abstract': 'One compelling vision of the future of materials discovery and design involves the use of machine learning (ML) models to predict materials properties and then rapidly find materials tailored for specific applications. However, realizing this vision requires both providing detailed uncertainty quantification (model prediction errors and domain of applicability) and making models readily usable. At present, it is common practice in the community to assess ML model performance only in terms of prediction accuracy (e.g., mean absolute error), while neglecting detailed uncertainty quantification and robust model accessibility and usability. Here, we demonstrate a practical method for realizing both uncertainty and accessibility features with a large set of models. We develop random forest ML models for 33 materials properties spanning an array of data sources (computational and experimental) and property types (electrical, mechanical, thermodynamic, etc.). All models have calibrated ensemble error bars to quantify prediction uncertainty and domain of applicability guidance enabled by kernel-density-estimate-based feature distance measures. All data and models are publicly hosted on the Garden-AI infrastructure, which provides an easy-to-use, persistent interface for model dissemination that permits models to be invoked with only a few lines of Python code. We demonstrate the power of this approach by using our models to conduct a fully ML-based materials discovery exercise to search for new stable, highly active perovskite oxide catalyst materials.',\n",
       " 'authors': ['Ryan Jacobs',\n",
       "  'Lane E. Schultz',\n",
       "  'Aristana Scourtas',\n",
       "  'KJ Schmidt',\n",
       "  'Owen Price-Skelly',\n",
       "  'Will Engler',\n",
       "  'Ian Foster',\n",
       "  'Ben Blaiszik',\n",
       "  'Paul M. Voyles',\n",
       "  'Dane Morgan'],\n",
       " 'link': 'http://arxiv.org/abs/2406.15650v1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd53fa2f-5d3c-4466-9aaf-b1f2781884c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following arXiv papers at the level of an advanced Ph.D. student, making interconnections between the papers where possible.\n",
      "                       First create a summary paragraph that includes the most important breakthroughs in the contained papers. \n",
      "                       Second, create a summary tweet thread describing the papers. \n",
      "                       Next, provide a section on interconnections where the information is grouped in a structured way that makes it easy to understand, rather than by each paper separately. \n",
      "                       Each paper should always be referenced by its link in markdown format. Be sure to include markdown style links to the papers and to references to the other papers. \n",
      "                       \n",
      "\n",
      "<paper>\n",
      "### Machine Learning Materials Properties with Accurate Predictions, Uncertainty Estimates, Domain Guidance, and Persistent Online Accessibility\n",
      "\n",
      "**Abstract:** One compelling vision of the future of materials discovery and design involves the use of machine learning (ML) models to predict materials properties and then rapidly find materials tailored for specific applications. However, realizing this vision requires both providing detailed uncertainty quantification (model prediction errors and domain of applicability) and making models readily usable. At present, it is common practice in the community to assess ML model performance only in terms of prediction accuracy (e.g., mean absolute error), while neglecting detailed uncertainty quantification and robust model accessibility and usability. Here, we demonstrate a practical method for realizing both uncertainty and accessibility features with a large set of models. We develop random forest ML models for 33 materials properties spanning an array of data sources (computational and experimental) and property types (electrical, mechanical, thermodynamic, etc.). All models have calibrated ensemble error bars to quantify prediction uncertainty and domain of applicability guidance enabled by kernel-density-estimate-based feature distance measures. All data and models are publicly hosted on the Garden-AI infrastructure, which provides an easy-to-use, persistent interface for model dissemination that permits models to be invoked with only a few lines of Python code. We demonstrate the power of this approach by using our models to conduct a fully ML-based materials discovery exercise to search for new stable, highly active perovskite oxide catalyst materials.\n",
      "\n",
      "**Authors:** Ryan Jacobs, Lane E. Schultz, Aristana Scourtas, KJ Schmidt, Owen Price-Skelly, Will Engler, Ian Foster, Ben Blaiszik, Paul M. Voyles, Dane Morgan\n",
      "\n",
      "[Link to paper](http://arxiv.org/abs/2406.15650v1)\n",
      "\n",
      "</paper>\n",
      "\n",
      "<paper>\n",
      "### Twins in rotational spectroscopy: Does a rotational spectrum uniquely identify a molecule?\n",
      "\n",
      "**Abstract:** Rotational spectroscopy is the most accurate method for determining structures of molecules in the gas phase. It is often assumed that a rotational spectrum is a unique \"fingerprint\" of a molecule. The availability of large molecular databases and the development of artificial intelligence methods for spectroscopy makes the testing of this assumption timely. In this paper, we pose the determination of molecular structures from rotational spectra as an inverse problem. Within this framework, we adopt a funnel-based approach to search for molecular twins, which are two or more molecules, which have similar rotational spectra but distinctly different molecular structures. We demonstrate that there are twins within standard levels of computational accuracy by generating rotational constants for many molecules from several large molecular databases, indicating the inverse problem is ill-posed. However, some twins can be distinguished by increasing the accuracy of the theoretical methods or by performing additional experiments.\n",
      "\n",
      "**Authors:** Marcus Schwarting, Nathan A. Seifert, Michael J. Davis, Ben Blaiszik, Ian Foster, Kirill Prozument\n",
      "\n",
      "[Link to paper](http://arxiv.org/abs/2404.04225v1)\n",
      "\n",
      "</paper>\n",
      "\n",
      "<paper>\n",
      "### Trillion Parameter AI Serving Infrastructure for Scientific Discovery: A Survey and Vision\n",
      "\n",
      "**Abstract:** Deep learning methods are transforming research, enabling new techniques, and ultimately leading to new discoveries. As the demand for more capable AI models continues to grow, we are now entering an era of Trillion Parameter Models (TPM), or models with more than a trillion parameters -- such as Huawei's PanGu-$\\Sigma$. We describe a vision for the ecosystem of TPM users and providers that caters to the specific needs of the scientific community. We then outline the significant technical challenges and open problems in system design for serving TPMs to enable scientific research and discovery. Specifically, we describe the requirements of a comprehensive software stack and interfaces to support the diverse and flexible requirements of researchers.\n",
      "\n",
      "**Authors:** Nathaniel Hudson, J. Gregory Pauloski, Matt Baughman, Alok Kamatar, Mansi Sakarvadia, Logan Ward, Ryan Chard, André Bauer, Maksim Levental, Wenyi Wang, Will Engler, Owen Price Skelly, Ben Blaiszik, Rick Stevens, Kyle Chard, Ian Foster\n",
      "\n",
      "[Link to paper](http://arxiv.org/abs/2402.03480v1)\n",
      "\n",
      "</paper>\n",
      "\n",
      "<paper>\n",
      "### Accelerating Electronic Stopping Power Predictions by 10 Million Times with a Combination of Time-Dependent Density Functional Theory and Machine Learning\n",
      "\n",
      "**Abstract:** Knowing the rate at which particle radiation releases energy in a material, the stopping power, is key to designing nuclear reactors, medical treatments, semiconductor and quantum materials, and many other technologies. While the nuclear contribution to stopping power, i.e., elastic scattering between atoms, is well understood in the literature, the route for gathering data on the electronic contribution has for decades remained costly and reliant on many simplifying assumptions, including that materials are isotropic. We establish a method that combines time-dependent density functional theory (TDDFT) and machine learning to reduce the time to assess new materials to mere hours on a supercomputer and provides valuable data on how atomic details influence electronic stopping. Our approach uses TDDFT to compute the electronic stopping contributions to stopping power from first principles in several directions and then machine learning to interpolate to other directions at a cost of 10 million times fewer core-hours. We demonstrate the combined approach in a study of proton irradiation in aluminum and employ it to predict how the depth of maximum energy deposition, the \"Bragg Peak,\" varies depending on incident angle -- a quantity otherwise inaccessible to modelers. The lack of any experimental information requirement makes our method applicable to most materials, and its speed makes it a prime candidate for enabling quantum-to-continuum models of radiation damage. The prospect of reusing valuable TDDFT data for training the model make our approach appealing for applications in the age of materials data science.\n",
      "\n",
      "**Authors:** Logan Ward, Ben Blaiszik, Cheng-Wei Lee, Troy Martin, Ian Foster, André Schleife\n",
      "\n",
      "[Link to paper](http://arxiv.org/abs/2311.00787v2)\n",
      "\n",
      "</paper>\n",
      "\n",
      "<paper>\n",
      "### Towards a Modular Architecture for Science Factories\n",
      "\n",
      "**Abstract:** Advances in robotic automation, high-performance computing (HPC), and artificial intelligence (AI) encourage us to conceive of science factories: large, general-purpose computation- and AI-enabled self-driving laboratories (SDLs) with the generality and scale needed both to tackle large discovery problems and to support thousands of scientists. Science factories require modular hardware and software that can be replicated for scale and (re)configured to support many applications. To this end, we propose a prototype modular science factory architecture in which reconfigurable modules encapsulating scientific instruments are linked with manipulators to form workcells, that can themselves be combined to form larger assemblages, and linked with distributed computing for simulation, AI model training and inference, and related tasks. Workflows that perform sets of actions on modules can be specified, and various applications, comprising workflows plus associated computational and data manipulation steps, can be run concurrently. We report on our experiences prototyping this architecture and applying it in experiments involving 15 different robotic apparatus, five applications (one in education, two in biology, two in materials), and a variety of workflows, across four laboratories. We describe the reuse of modules, workcells, and workflows in different applications, the migration of applications between workcells, and the use of digital twins, and suggest directions for future work aimed at yet more generality and scalability. Code and data are available at https://ad-sdl.github.io/wei2023 and in the Supplementary Information\n",
      "\n",
      "**Authors:** Rafael Vescovi, Tobias Ginsburg, Kyle Hippe, Doga Ozgulbas, Casey Stone, Abraham Stroka, Rory Butler, Ben Blaiszik, Tom Brettin, Kyle Chard, Mark Hereld, Arvind Ramanathan, Rick Stevens, Aikaterini Vriza, Jie Xu, Qingteng Zhang, Ian Foster\n",
      "\n",
      "[Link to paper](http://arxiv.org/abs/2308.09793v2)\n",
      "\n",
      "</paper>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# surprised bc add all of the paper with the summary in single str ! \n",
    "print (input_for_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e58eb5-bc2e-4656-8cc3-ccf39ede58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The open ai api with payment we here get 429 response \n",
    "# system_prompt = \"You are modeling the mind of a researcher who has obtained a PhD in the field of study for the papers retrieved.\"\n",
    "\n",
    "# # models \"gpt-4-turbo\", \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "# oai = get_openai(input_for_summary, \n",
    "#                  model=\"gpt-3.5-turbo-0125\",\n",
    "#                  system_prompt=system_prompt,\n",
    "#                  max_tokens=2000,\n",
    "#                  api_key=openai_api_key\n",
    "#                 )\n",
    "# display(Markdown(oai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df6fb2b-26e4-479a-bd0b-a9d0e64bada1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Summary Paragraph:\n",
       "\n",
       "The papers presented here showcase significant breakthroughs in the field of materials science and scientific discovery. [Jacobs et al.](http://arxiv.org/abs/2406.15650v1) demonstrate a practical method for developing machine learning models that provide both accurate property predictions and detailed uncertainty quantification, making the models readily usable and accessible through the Garden-AI infrastructure. [Schwarting et al.](http://arxiv.org/abs/2404.04225v1) explore the inverse problem of determining molecular structures from rotational spectra, revealing the existence of \"molecular twins\" that have similar spectra but distinct structures, highlighting the need for increased accuracy in theoretical methods and experiments. [Hudson et al.](http://arxiv.org/abs/2402.03480v1) present a vision for a comprehensive software stack and interfaces to support the diverse and flexible requirements of researchers in the era of Trillion Parameter Models (TPMs). [Ward et al.](http://arxiv.org/abs/2311.00787v2) develop a method that combines time-dependent density functional theory and machine learning to dramatically accelerate the prediction of electronic stopping power, a crucial quantity for designing various technologies. Finally, [Vescovi et al.](http://arxiv.org/abs/2308.09793v2) propose a modular architecture for \"science factories,\" large-scale, AI-enabled self-driving laboratories that can support a wide range of scientific applications and workflows.\n",
       "\n",
       "Summary Tweet Thread:\n",
       "\n",
       "1/ Exciting breakthroughs in materials science and scientific discovery! 🔬🧪\n",
       "[Jacobs et al.](http://arxiv.org/abs/2406.15650v1) develop ML models with accurate predictions, uncertainty estimates, and easy accessibility through Garden-AI.\n",
       "\n",
       "2/ [Schwarting et al.](http://arxiv.org/abs/2404.04225v1) explore the inverse problem of determining molecular structures from rotational spectra, revealing the existence of \"molecular twins\" with similar spectra but distinct structures.\n",
       "\n",
       "3/ [Hudson et al.](http://arxiv.org/abs/2402.03480v1) present a vision for a comprehensive software stack to support the diverse needs of researchers in the era of Trillion Parameter Models (TPMs).\n",
       "\n",
       "4/ [Ward et al.](http://arxiv.org/abs/2311.00787v2) develop a method combining TDDFT and ML to dramatically accelerate the prediction of electronic stopping power, a crucial quantity for various technologies.\n",
       "\n",
       "5/ [Vescovi et al.](http://arxiv.org/abs/2308.09793v2) propose a modular architecture for \"science factories\" - large-scale, AI-enabled self-driving labs that can support a wide range of scientific applications and workflows.\n",
       "\n",
       "Interconnections:\n",
       "\n",
       "The papers presented here showcase a range of advancements in materials science and scientific discovery, with several interconnections and synergies.\n",
       "\n",
       "**Uncertainty Quantification and Model Accessibility**:\n",
       "The work by [Jacobs et al.](http://arxiv.org/abs/2406.15650v1) on developing machine learning models with calibrated uncertainty estimates and easy-to-use interfaces through the Garden-AI infrastructure is a crucial step towards making these powerful predictive tools more accessible and usable for researchers. This aligns with the vision presented by [Hudson et al.](http://arxiv.org/abs/2402.03480v1) for a comprehensive software stack to support the diverse needs of researchers working with large-scale AI models.\n",
       "\n",
       "**Inverse Problems in Molecular Spectroscopy**:\n",
       "The discovery of \"molecular twins\" by [Schwarting et al.](http://arxiv.org/abs/2404.04225v1) highlights the challenges in uniquely identifying molecular structures from rotational spectra, an inverse problem. This work underscores the need for increased accuracy in theoretical methods and experimental techniques, as mentioned by the authors. The ability to rapidly predict electronic stopping power using the combined TDDFT and ML approach developed by [Ward et al.](http://arxiv.org/abs/2311.00787v2) could potentially aid in the interpretation of molecular spectra and the identification of molecular structures.\n",
       "\n",
       "**Towards Modular and Scalable Scientific Platforms**:\n",
       "The modular architecture for \"science factories\" proposed by [Vescovi et al.](http://arxiv.org/abs/2308.09793v2) aligns with the broader vision of scalable, AI-enabled scientific platforms. The ability to reuse modules, workcells, and workflows across different applications, as demonstrated in their work, could facilitate the integration of the advanced predictive tools and models developed in the other papers, such as the machine learning models from [Jacobs et al.](http://arxiv.org/abs/2406.15650v1) and the electronic stopping power predictions from [Ward et al.](http://arxiv.org/abs/2311.00787v2).\n",
       "\n",
       "Overall, these papers collectively highlight the significant progress being made in materials science and scientific discovery, with a focus on developing accurate predictive models, addressing inverse problems, and creating scalable, modular platforms to enable the next generation of scientific research and discovery."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"You are modeling the mind of a researcher who has obtained a PhD in the field of study for the papers retrieved.\"\n",
    "\n",
    "# Other models \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"\n",
    "# so the claud api is just giving 5$ for free and after that purchase is neeeded \n",
    "anth = get_anthropic(input_for_summary, \n",
    "                         api_key=claude_api_key,\n",
    "                         model=\"claude-3-haiku-20240307\",\n",
    "                         system_prompt=system_prompt, \n",
    "                         max_tokens=2000, \n",
    "                         temperature=0)\n",
    "display(Markdown(anth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db33b66-c69a-49fe-bcbf-6a7c57afcc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Summary Paragraph:\n",
       "\n",
       "The presented papers showcase significant advancements in the field of machine learning (ML) for materials science and discovery. [Jacobs et al.](http://arxiv.org/abs/2406.15650v1) developed a practical method for providing detailed uncertainty quantification and robust accessibility for a large set of ML models predicting various materials properties, enabling more reliable and usable predictions. [Schwarting et al.](http://arxiv.org/abs/2404.04225v1) explored the inverse problem of determining molecular structures from rotational spectra, revealing the existence of \"molecular twins\" with similar spectra but distinct structures, highlighting the need for increased accuracy in theoretical methods or additional experiments. [Ward et al.](http://arxiv.org/abs/2311.00787v2) combined time-dependent density functional theory and machine learning to dramatically accelerate the prediction of electronic stopping power, a crucial quantity for designing nuclear reactors, medical treatments, and quantum materials. Finally, [Vescovi et al.](http://arxiv.org/abs/2308.09793v2) proposed a modular architecture for \"science factories\" - large, general-purpose, computation- and AI-enabled self-driving laboratories capable of supporting a wide range of scientific applications and workflows.\n",
       "\n",
       "Summary Tweet Thread:\n",
       "\n",
       "1/ Exciting breakthroughs in materials science and discovery! 🔬🤖\n",
       "@RyanJacobs_UW et al. developed ML models with uncertainty quantification and accessibility for 33 materials properties. [http://arxiv.org/abs/2406.15650v1]\n",
       "\n",
       "2/ @mschwarting et al. explored the inverse problem of determining molecular structures from rotational spectra, revealing the existence of \"molecular twins\" with similar spectra but distinct structures. [http://arxiv.org/abs/2404.04225v1]\n",
       "\n",
       "3/ @LoganWard et al. combined TDDFT and ML to dramatically accelerate the prediction of electronic stopping power, a crucial quantity for nuclear, medical, and quantum materials design. [http://arxiv.org/abs/2311.00787v2]\n",
       "\n",
       "4/ @RafaelVescovi et al. proposed a modular architecture for \"science factories\" - general-purpose, computation- and AI-enabled self-driving labs to support a wide range of scientific applications. [http://arxiv.org/abs/2308.09793v2]\n",
       "\n",
       "Interconnections:\n",
       "\n",
       "The presented papers showcase a range of advancements in the use of machine learning and computational techniques to accelerate scientific discovery and materials design.\n",
       "\n",
       "**Uncertainty Quantification and Accessibility:**\n",
       "[Jacobs et al.](http://arxiv.org/abs/2406.15650v1) developed a practical method for providing detailed uncertainty quantification and robust accessibility for a large set of ML models predicting various materials properties. This work is crucial for enabling reliable and usable ML predictions in materials science, which can then be leveraged by other researchers and applications.\n",
       "\n",
       "**Inverse Problems in Molecular Structure Determination:**\n",
       "[Schwarting et al.](http://arxiv.org/abs/2404.04225v1) explored the inverse problem of determining molecular structures from rotational spectra, revealing the existence of \"molecular twins\" with similar spectra but distinct structures. This highlights the need for increased accuracy in theoretical methods or additional experiments to uniqu"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Other models \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"\n",
    "# same model different mode (real time answer) \n",
    "# Call the function with your input\n",
    "get_streaming_anthropic(input_for_summary, \n",
    "                             model=\"claude-3-haiku-20240307\",\n",
    "                             api_key=claude_api_key,\n",
    "                             system_prompt=system_prompt, \n",
    "                             max_tokens=750, \n",
    "                             temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0291ba72-a899-4bb6-b34d-a094d92a8e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
